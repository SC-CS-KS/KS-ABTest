# 假设检验

假设检验是依据反证法思想，首先对总体参数提出某种假设（原假设），然后利用样本信息去判断这个假设是否成立的过程。  

在A/B Test中一般有两种假设：
原假设 H0：我们反对的假设（样本与总体或样本与样本间的差异是由抽样误差引起的）
备择假设 H1：我们坚持的假设（样本与总体或样本与样本间存在本质差异）  

***假设检验的目标是拒绝原假设***，它的核心是证伪。  

## 案例

假设我们有版本A和版本B，用 $\mu_A$ 和 $\mu_B$ 分别表示版本A和版本B里面指标的均值。
在频率统计里面，假设检验从一对假设开始：  
$H_0 : \mu_A = \mu_B$  
$H_1 : \mu_A = \mu_B$  

在频率统计中，我们通常假设 $H_0$ 是对的，然后构造如下的统计量：  
$T = \frac{\hat\mu_B - \hat\mu_A}{\sqrt{\hat{var}(\hat\mu_B) + \hat{var}(\hat\mu_A)}}$

其中 $\hat\mu_B$ 和 $\hat\mu_A$ 分别是基于有限的随机样本的对 $\mu_B$ 和$\mu_B$ 的估计。  

既然 $\hat\mu_B$ 和 $\hat\mu_A$ 是基于有限样本的估计，那么它们都是具有随机性的。
用 $\hat{var}(\hat\mu_B)$ 和 $\hat{var}(\hat\mu_A)$来分别表示 $\hat\mu_B$ 和 $\hat\mu_A$  的方差。  

由于在实践中，我们通常不知道${var}(\hat\mu_B)$ 和 ${var}(\hat\mu_A)$，所以我们用它们的估计 $\hat{var}(\hat\mu_B)$ 和 $\hat{var}(\hat\mu_A)$ 来代替。  

由中心极限定理我们知道 $\hat\mu_B - \hat\mu_A$ 服从均值为 ${\mu_B - \mu_A}$，方差为${var}(\hat\mu_B)$ 和 ${var}(\hat\mu_A)$的正态分布。  

在$H_0$是对的条件下，这个正态分布的均值为0。  

$\hat{var}(\hat\mu_B)$ 和 $\hat{var}(\hat\mu_A)$分别是B和A中的样本方差除以样本数。  
理论上可以证明$\frac{\hat{var}(\hat\mu_B) + \hat{var}(\hat\mu_A)}{{var}(\hat\mu_B) + {var}(\hat\mu_A)}$近似服从$\chi^2(n_A + n_B -2)$，其中$n_A$和$n_B$分别是A和B中的样本数。  
而$\frac{\hat\mu_B - \hat\mu_A}{\sqrt{{var}(\hat\mu_B) + {var}(\hat\mu_A)}}$服从标准正态分布，并且我们可以证明 ${var}(\hat\mu_B) + {var}(\hat\mu_A)$ 和 $\hat\mu_B - \hat\mu_A$ 是近似独立的。  

上面的 $T$ 统计量写成下面等式右侧的形式：

$\frac{\hat\mu_B - \hat\mu_A}{\sqrt{\hat{var}(\hat\mu_B) + \hat{var}(\hat\mu_A)}} = \frac{{\hat\mu_B - \hat\mu_A}/{\sqrt{{var}(\hat\mu_B) + {var}(\hat\mu_A)}}}{\sqrt{{(\hat{var}(\hat\mu_B) + \hat{var}(\hat\mu_A))}/{(\sqrt{{var}(\hat\mu_B) + {var}(\hat\mu_A)}})}}$  

在$H_0$为真的情况下，上面等式的右边分子服从标准正态分布，分母是 $\chi^2(n_A + n_B -2)$ 分布开根号，并且分子和分母近似独立，  
因此根据$t$分布的定义，上面等式两边都服从 $t(n_A + n_B -2)$

所以上面这种假设检验的方法通常被叫做$t$检验。这里的推导很多细节被略过。感兴趣的同学可以参考基础的概率统计课本。  
互联网上的实验通常样本量很大，而当自由度很大时，$t$分布 和 标准正态分布$N\{0,1\}$ 基本上没有区别。  
所以在互联网实验里面我们通常就近似地认为$T$统计量服从标准正态分布。  

## $p$值
介绍完统计量，我们来介绍$p$值的概念。
$p$值表示的是当$H_0$为真时，我们观察到比当前统计量的值更加极端的值的概率。  
数学表达式为 $P(T>|t||H_0)$。

## 第一类错误

在假设检验中，我们会犯两类错误。  
第一类错误是当$H_0$为真拒绝$H_0$。  

## 第二类错误

第二类错误是当$H_0$为伪接受$H_0$。  

这两类错误是相互冲突的，即我们可以通过提高一类错误的概率来降低另外一类错误的概率。  
举两个极端的例子：
我们可以总是拒绝$H_0$从而把第二类错误的概率控制为0，而第一类错误的概率为1。  
另一个极端是我们可以总是接受$H_0$，而把第一类错误的概率控制为0，而第二类错误的概率为1。  
因此，我们在实践中的做法是控制第一类错误的概率在一定的阈值以下去减少第二类错误。
通常我们选定第一类错误概率的阈值为0.05，只要观察到的$p$值小于0.05我们就拒绝$H_0$，  
这样我们就把第一类错误的概率控制在0.05。  
优化第二类错误的方法也很多。  

